import torch
from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler
from PIL import Image, ImageDraw, ImageFont
import os
import argparse
import re
import random

def get_all_checkpoints(folder_path):
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€å†…ã«ã‚ã‚‹ã™ã¹ã¦ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¨æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã™ã‚‹ã€‚
    
    Returns:
        List of tuples: [(step_count, path, name_str), ...]
        Sorted by step count.
    """
    checkpoints = []
    
    # 1. æœ€çµ‚ãƒ¢ãƒ‡ãƒ« (pytorch_lora_weights.safetensors)
    final_weight = os.path.join(folder_path, "pytorch_lora_weights.safetensors")
    if os.path.exists(final_weight):
        # ä¾¿å®œä¸Šã€éå¸¸ã«å¤§ããªã‚¹ãƒ†ãƒƒãƒ—æ•°ã¨ã—ã¦æ‰±ã†ã‹ã€ãƒ•ãƒ©ã‚°ã§ç®¡ç†
        checkpoints.append((999999999, final_weight, "Final"))

    # 2. é€”ä¸­çµŒé (checkpoint-xxxx)
    if os.path.exists(folder_path):
        for d in os.listdir(folder_path):
            if d.startswith("checkpoint-"):
                try:
                    step = int(d.split("-")[1])
                    # checkpointãƒ•ã‚©ãƒ«ãƒ€ã®ä¸­ã®safetensorsã‚’æ¢ã™
                    ckpt_file = os.path.join(folder_path, d, "pytorch_lora_weights.safetensors")
                    if os.path.exists(ckpt_file):
                        checkpoints.append((step, ckpt_file, f"Step-{step}"))
                except ValueError:
                    continue
    
    # ã‚¹ãƒ†ãƒƒãƒ—é †ã«ã‚½ãƒ¼ãƒˆ
    checkpoints.sort(key=lambda x: x[0])
    return checkpoints

def find_lora_weight(folder_path, target_step="latest"):
    """
    (æ—§é–¢æ•°: å˜ä¸€ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ¢ã™ç”¨)
    """
    all_ckpts = get_all_checkpoints(folder_path)
    if not all_ckpts:
        return None, None

    if target_step == "latest":
        return all_ckpts[-1][1], all_ckpts[-1][2]
    
    elif target_step == "final":
        # Finalã‚’æ¢ã™
        for step, path, name in all_ckpts:
            if name == "Final":
                return path, name
        # ãªã‘ã‚Œã°æœ€æ–°
        return all_ckpts[-1][1], all_ckpts[-1][2]
        
    elif str(target_step).isdigit():
        target = int(target_step)
        for step, path, name in all_ckpts:
            if step == target:
                return path, name
        print(f"âš ï¸ Step {target} not found. Using latest.")
        return all_ckpts[-1][1], all_ckpts[-1][2]

    return None, None

def main():
    parser = argparse.ArgumentParser(description="Evaluate and compare LoRA models from a directory")
    parser.add_argument("--output_dir", type=str, default="/content/drive/MyDrive/github/diffusers/evaluations", help="Root directory to save results")
    parser.add_argument("--models_dir", type=str, default=None, help="Root directory containing experiment folders to scan")
    parser.add_argument("--target_step", type=str, default="latest", help="'latest', 'final', specific int, or 'all' to generate for all checkpoints.")
    parser.add_argument("--base_model", type=str, default="runwayml/stable-diffusion-v1-5", help="Base model path or ID")
    parser.add_argument("--lora_paths", type=str, nargs='+', help="Specific LoRA paths (Optional). Overrides models_dir scan.")
    parser.add_argument("--random_seeds", type=int, default=0, help="Number of random seeds to use. If 0 (default), uses fixed seeds [42, 123].")
    
    args = parser.parse_args()

    # 1. æ¯”è¼ƒå¯¾è±¡ã®LoRAãƒªã‚¹ãƒˆã‚’ä½œæˆ
    lora_candidates = {} # name -> folder_path

    if args.lora_paths:
        for item in args.lora_paths:
            if ":" in item:
                name, path = item.split(":", 1)
                lora_candidates[name] = path
            else:
                name = os.path.basename(item.rstrip("/"))
                lora_candidates[name] = item
    
    elif args.models_dir and os.path.exists(args.models_dir):
        print(f"ğŸ“‚ Scanning models in: {args.models_dir}")
        for d in sorted(os.listdir(args.models_dir)):
            full_path = os.path.join(args.models_dir, d)
            if os.path.isdir(full_path):
                if os.path.exists(os.path.join(full_path, "pytorch_lora_weights.safetensors")) or \
                   any(sub.startswith("checkpoint-") for sub in os.listdir(full_path)):
                    lora_candidates[d] = full_path
    else:
        # Colab Default
        default_dir = "/content/drive/MyDrive/github/diffusers/outputs"
        if os.path.exists(default_dir):
            print(f"â„¹ï¸ No paths provided. Scanning default Colab output dir: {default_dir}")
            for d in sorted(os.listdir(default_dir)):
                full_path = os.path.join(default_dir, d)
                if os.path.isdir(full_path):
                    lora_candidates[d] = full_path
        else:
            print("âŒ No models found. Please specify --models_dir or --lora_paths.")
            return

    if not lora_candidates:
        print("âŒ No valid LoRA model folders found.")
        return

    print(f"ğŸ” Found {len(lora_candidates)} models: {list(lora_candidates.keys())}")

    # 2. ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
    device = "cuda" if torch.cuda.is_available() else "cpu"
    dtype = torch.float16 if device == "cuda" else torch.float32
    
    print(f"ğŸš€ Loading base model: {args.base_model}")
    print(f"   Device: {device}, Dtype: {dtype}")

    pipe = StableDiffusionPipeline.from_pretrained(
        args.base_model,
        torch_dtype=dtype
    ).to(device)
    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config, use_karras_sigmas=True)
    
    # CPUã®å ´åˆã€ãƒ¡ãƒ¢ãƒªç¯€ç´„ã®ãŸã‚ã«attention slicingã‚’æœ‰åŠ¹åŒ–
    if device == "cpu":
        pipe.enable_attention_slicing()

    # 3. æ¯”è¼ƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    prompts = [
        ("Male High", "a photo of a male face, high score impression"),
        ("Male Low",  "a photo of a male face, low score impression"),
        ("Fem High",  "a photo of a female face, high score impression"),
        ("Fem Low",   "a photo of a female face, low score impression"),
    ]
    
    # Seedè¨­å®š
    if args.random_seeds > 0:
        seeds = [random.randint(0, 2**32 - 1) for _ in range(args.random_seeds)]
        print(f"ğŸ² Using {args.random_seeds} random seeds: {seeds}")
    else:
        seeds = [42, 123]
        print(f"ğŸ”’ Using fixed seeds: {seeds}")
    
    os.makedirs(args.output_dir, exist_ok=True)
    
    # 4. ç”Ÿæˆãƒ«ãƒ¼ãƒ—
    for model_name, folder_path in lora_candidates.items():
        print(f"\n=========================================================")
        print(f"ğŸš€ Processing Model: {model_name}")
        print(f"=========================================================")

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¹ãƒ†ãƒƒãƒ—ã®ãƒªã‚¹ãƒˆã‚’å–å¾—
        targets = []
        if args.target_step == "all":
            targets = get_all_checkpoints(folder_path)
            if not targets:
                print(f"âš ï¸ No checkpoints found in {folder_path}")
                continue
        else:
            path, name = find_lora_weight(folder_path, args.target_step)
            if path:
                targets = [(0, path, name)] # stepæ•°ã¯ãƒ€ãƒŸãƒ¼
            else:
                print(f"âš ï¸ Target step {args.target_step} not found for {model_name}")
                continue

        # ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
        model_output_dir = os.path.join(args.output_dir, model_name)
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã®å ´åˆã¯ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
        if args.random_seeds > 0:
            model_output_dir = os.path.join(model_output_dir, "random_seeds")
            
        os.makedirs(model_output_dir, exist_ok=True)
        print(f"ğŸ“‚ Output Folder: {model_output_dir}")

        for step_val, weight_path, step_name in targets:
            print(f"  ğŸ‘‰ Testing: {step_name} ...", end="", flush=True)

            try:
                pipe.unload_lora_weights()
                pipe.load_lora_weights(os.path.dirname(weight_path), weight_name=os.path.basename(weight_path))
            except Exception as e:
                print(f" [Error] {e}")
                continue

            for seed in seeds:
                images = []
                generator = torch.Generator(device).manual_seed(seed)
                
                for label, prompt in prompts:
                    image = pipe(
                        prompt, 
                        num_inference_steps=30, 
                        guidance_scale=7.5, 
                        generator=generator
                    ).images[0]
                    images.append(image)
                
                # ã‚°ãƒªãƒƒãƒ‰çµåˆ
                w, h = images[0].size
                grid = Image.new('RGB', (w * len(images), h))
                for i, img in enumerate(images):
                    grid.paste(img, (w * i, 0))
                
                # ãƒ•ã‚¡ã‚¤ãƒ«å: Step-XXXX_seedYY.png (ãƒ¢ãƒ‡ãƒ«åã¯ãƒ•ã‚©ãƒ«ãƒ€åã«ã‚ã‚‹ã®ã§çœç•¥å¯ã ãŒã€å¿µã®ãŸã‚)
                save_filename = f"{step_name}_seed{seed}.png"
                save_path = os.path.join(model_output_dir, save_filename)
                grid.save(save_path)
            
            print(" Done.")

    print(f"\nâœ¨ All evaluations finished. Results in: {args.output_dir}")

if __name__ == "__main__":
    main()