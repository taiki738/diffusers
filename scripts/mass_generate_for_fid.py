import os
import argparse
import torch
import diffusers
from pathlib import Path
from diffusers import StableDiffusionPipeline, StableDiffusionXLPipeline, AutoencoderKL

# diffusers„ÅÆ„É≠„Ç∞„ÇíÊäëÂà∂ (Ë≠¶Âëä„Å™„Å©„ÇíÊ∂à„Åô)
diffusers.utils.logging.set_verbosity_error()

MAPPING = {
    "lora_baseline": ("stable-diffusion-v1-5", False, "latest"),
    "lora_rank4_lr5e5": ("stable-diffusion-v1-5", False, "latest"),
    "lora_rank16_lr1e4": ("stable-diffusion-v1-5", False, "latest"),
    "lora_rank16_lr5e5": ("stable-diffusion-v1-5", False, "latest"),

    "sdxl_lora_rank16_prodigy": ("sdxl-base-1.0", True, "latest"),
    "sdxl_lora_rank32_prodigy": ("sdxl-base-1.0", True, "latest"),
    "realvisxl_lora_rank16_prodigy": ("RealVisXL_V4.0", True, "latest"),

    "lora_rank16_lr5e5_trigger_ohwx": ("stable-diffusion-v1-5", False, "latest"),
    "sdxl_lora_rank16_prodigy_trigger_ohwx": ("sdxl-base-1.0", True, "latest"),
    "realvisxl_lora_rank16_prodigy_trigger_ohwx": ("RealVisXL_V4.0", True, "latest"),
}

def sanitize_prompt(prompt):
    """„Éó„É≠„É≥„Éó„Éà„Çí„Éï„Ç©„É´„ÉÄÂêç„Å®„Åó„Å¶‰Ωø„Åà„ÇãÂΩ¢Âºè„Å´Â§âÊèõ"""
    safe_name = prompt.replace(",", "").replace(".", "").replace(" ", "_").replace("(", "").replace(")", "")
    return safe_name[:100]

def get_target_checkpoint(exp_dir, target_step_cfg, default_step=None):
    """ÊåáÂÆö„Åï„Çå„ÅüË®≠ÂÆö„Å´Âü∫„Å•„ÅÑ„Å¶„ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà„Éë„Çπ„ÇíÂèñÂæó"""
    # ÂÖ®„ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„ÉàÂèñÂæó
    checkpoints = sorted([d for d in exp_dir.iterdir() if d.name.startswith("checkpoint-")], 
                         key=lambda x: int(x.name.split("-")[1]))
    
    if not checkpoints:
        return None

    ckpt_map = {int(d.name.split("-")[1]): d for d in checkpoints}

    if isinstance(target_step_cfg, int):
        if target_step_cfg in ckpt_map:
            return ckpt_map[target_step_cfg]

    if default_step is not None:
        if default_step in ckpt_map:
            return ckpt_map[default_step]

    return checkpoints[-1]

def generate_images(args):
    root_dir = Path(args.outputs_dir)
    models_root = Path(args.models_root)
    samples_root = root_dir / "samples"
    samples_root.mkdir(exist_ok=True)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    dtype = torch.float16 if device == "cuda" else torch.float32

    for exp_name, (base_name, is_sdxl, target_step_cfg) in MAPPING.items():
        exp_dir = root_dir / exp_name
        if not exp_dir.exists():
            continue

        ckpt_path = get_target_checkpoint(exp_dir, target_step_cfg, args.default_step)
        if not ckpt_path:
            continue
            
        step = ckpt_path.name.split("-")[1]
        
        # „Éó„É≠„É≥„Éó„Éà„ÅÆÁµÑ„ÅøÁ´ã„Å¶
        final_prompt = args.prompt.replace("{gender}", args.gender)
        if "trigger" in exp_name.lower() and "ohwx" not in final_prompt:
             final_prompt = final_prompt.replace("a photo of", "a photo of ohwx")

        # Âá∫ÂäõÂÖà„Éë„Çπ‰ΩúÊàê: samples/{ÂÆüÈ®ìÂêç_„É¢„Éá„É´_step}/{„Éó„É≠„É≥„Éó„ÉàÂêç}/
        prompt_dir_name = sanitize_prompt(final_prompt)
        base_save_dir = samples_root / f"{exp_name}_{base_name}_step{step}"
        target_save_dir = base_save_dir / prompt_dir_name
        
        # „Çπ„Éû„Éº„Éà„É¨„Ç∏„É•„Éº„É†: Êó¢„Å´Â≠òÂú®„Åô„Çã„Éï„Ç°„Ç§„É´Êï∞„ÇíÁ¢∫Ë™ç
        existing_images = list(target_save_dir.glob("*.png")) if target_save_dir.exists() else []
        current_count = len(existing_images)
        
        if current_count >= args.num_images:
            print(f"‚úÖ {exp_name} ({step}): Already {current_count} images.")
            continue
            
        target_save_dir.mkdir(parents=True, exist_ok=True)

        print(f"üöÄ {exp_name} ({step}) -> Existing: {current_count}. Target: {args.num_images}")

        try:
            # „Éë„Ç§„Éó„É©„Ç§„É≥ÊßãÁØâ
            base_model_path = models_root / base_name
            if is_sdxl:
                vae_path = "madebyollin/sdxl-vae-fp16-fix"
                pipe = StableDiffusionXLPipeline.from_pretrained(
                    str(base_model_path), 
                    torch_dtype=dtype, 
                    vae=AutoencoderKL.from_pretrained(vae_path, torch_dtype=dtype)
                )
                width, height = 1024, 1024
            else:
                pipe = StableDiffusionPipeline.from_pretrained(
                    str(base_model_path),
                    torch_dtype=dtype
                )
                width, height = 512, 512
            
            # ÂÜÖÈÉ®„ÅÆ„Éó„É≠„Ç∞„É¨„Çπ„Éê„Éº„ÇíÁÑ°ÂäπÂåñ
            pipe.set_progress_bar_config(disable=True)
            
            pipe.to(device)
            pipe.load_lora_weights(str(ckpt_path))
            
            # ÁîüÊàê„É´„Éº„Éó („Éê„ÉÉ„ÉÅÂØæÂøú)
            needed_images = args.num_images - current_count
            
            for i in range(0, needed_images, args.batch_size):
                # ‰ªäÂõû„ÅÆ„Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫
                current_batch_size = min(args.batch_size, needed_images - i)
                
                # „Ç∑„Éº„ÉâÁîüÊàê
                seeds = [torch.randint(0, 2**32 - 1, (1,)).item() for _ in range(current_batch_size)]
                generators = [torch.Generator(device=device).manual_seed(s) for s in seeds]
                
                images = pipe(
                    final_prompt, 
                    num_inference_steps=30, 
                    height=height,
                    width=width,
                    generator=generators,
                    num_images_per_prompt=current_batch_size
                ).images
                
                # ‰øùÂ≠ò
                for idx, image in enumerate(images):
                    global_idx = current_count + i + idx
                    seed = seeds[idx]
                    image.save(target_save_dir / f"{global_idx:04d}_seed{seed}.png")
                
                # ÈÄ≤ÊçóË°®Á§∫
                completed = current_count + i + current_batch_size
                if completed % 100 == 0 or completed >= args.num_images:
                    print(f"\r      - Progress: {completed} / {args.num_images} images generated.", end="", flush=True)
                
            print(" Done.")
            del pipe
            torch.cuda.empty_cache()
            
        except Exception as e:
            print(f"\n   ‚ùå Error processing {exp_name}: {e}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Mass generate images for FID evaluation from LoRA checkpoints.")
    parser.add_argument("--outputs_dir", type=str, required=True, help="Path to diffusers/outputs")
    parser.add_argument("--models_root", type=str, required=True, help="Path to models directory")
    parser.add_argument("--num_images", type=int, default=1000, help="Total number of images to ensure per model")
    parser.add_argument("--default_step", type=int, default=5000, help="Default step to use if available")
    parser.add_argument("--gender", type=str, default="male", choices=["male", "female"], help="Gender to replace {gender} in prompt")
    parser.add_argument("--prompt", type=str, default="a photo of a {gender} face, high score impression", help="Prompt template")
    parser.add_argument("--batch_size", type=int, default=1, help="Batch size for generation")
    
    args = parser.parse_args()
    generate_images(args)
