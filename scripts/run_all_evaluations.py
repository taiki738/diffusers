import os
import argparse
import json
import pandas as pd
from pathlib import Path
from tqdm import tqdm
import subprocess

# ==========================================
# Configuration
# ==========================================

# å®Ÿé¨“IDã¨ãƒ•ã‚©ãƒ«ãƒ€åã®ãƒãƒƒãƒ”ãƒ³ã‚° (è«–æ–‡ã®è¡¨ã«åŸºã¥ã)
EXP_MAPPING = {
    "lora_baseline": "EXP-SD-R4-L1", # ä»® (configç¢ºèªè¦)
    "lora_rank4_lr5e5": "EXP-SD-R4-L2",
    "lora_rank16_lr1e4": "EXP-SD-R16-L1",
    "lora_rank16_lr5e5": "EXP-SD-R16-L2",

    "sdxl_lora_rank16_prodigy": "EXP-XL-R16",
    "sdxl_lora_rank32_prodigy": "EXP-XL-R32",
    "realvisxl_lora_rank16_prodigy": "EXP-RV-R16",
    
    "lora_rank16_lr5e5_trigger_ohwx": "EXP-SD-TRIG",
    "sdxl_lora_rank16_prodigy_trigger_ohwx": "EXP-XL-TRIG",
    "realvisxl_lora_rank16_prodigy_trigger_ohwx": "EXP-RV-TRIG",
}

def run_command(cmd):
    """ã‚·ã‚§ãƒ«ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã€ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°ä¾‹å¤–ã‚’æŠ•ã’ã‚‹"""
    print(f"ğŸš€ Running: {cmd}")
    ret = os.system(cmd)
    if ret != 0:
        print(f"âŒ Command failed with return code {ret}")
        # ç¶šè¡Œå¯èƒ½ãªã‚¨ãƒ©ãƒ¼ã‚‚ã‚ã‚‹ã®ã§ã€ã“ã“ã§ã¯ãƒ­ã‚°å‡ºã—ã«ã¨ã©ã‚ã‚‹

def get_dataset_path(base_dir, gender, impression):
    """æ¡ä»¶ã«å¯¾å¿œã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹ã‚’è¿”ã™"""
    # ä¾‹: .../male/OK_4.0
    imp_folder = "OK_4.0" if impression == "high" else "not-OK_2.0"
    return os.path.join(base_dir, gender, imp_folder)

def main():
    parser = argparse.ArgumentParser(description="Run comprehensive evaluation for all experiments.")
    parser.add_argument("--dataset_root", type=str, required=True, help="Root of extracted dataset (e.g., /content/ffhq_for_survey)")
    parser.add_argument("--gen_root", type=str, required=True, help="Root of generated images (e.g., .../evaluations/samples)")
    parser.add_argument("--output_dir", type=str, required=True, help="Directory to save evaluation results")
    parser.add_argument("--num_trials", type=int, default=100, help="Number of trials for Baseline FID bootstrap")
    parser.add_argument("--skip_baseline", action="store_true", help="Skip baseline calculation if already done")
    
    args = parser.parse_args()
    
    os.makedirs(args.output_dir, exist_ok=True)
    
    # -------------------------------------------------
    # 1. Baseline FID Calculation (Bootstrap 100 trials)
    # -------------------------------------------------
    conditions = [
        ("male", "high"), ("male", "low"),
        ("female", "high"), ("female", "low")
    ]
    
    baseline_results = {}
    
    if not args.skip_baseline:
        print("\nğŸ”µ Step 1: Calculating Baseline FID (Internal Diversity)...")
        for gender, impression in conditions:
            data_path = get_dataset_path(args.dataset_root, gender, impression)
            save_name = f"baseline_{gender}_{impression}.json"
            save_path = os.path.join(args.output_dir, save_name)
            
            if os.path.exists(save_path):
                print(f"   â© Skipping {save_name} (Already exists)")
                with open(save_path, 'r') as f:
                    baseline_results[f"{gender}_{impression}"] = json.load(f)
                continue
                
            cmd = (
                f"python scripts/eval_lora_metrics.py "
                f"--mode baseline_check "
                f"--full_data_dir {data_path} "
                f"--num_trials {args.num_trials} "
                f"--val_ratio 0.5 "
                f"--output_json {save_path}"
            )
            run_command(cmd)
            
            # èª­ã¿è¾¼ã‚“ã§ãƒ¡ãƒ¢ãƒªã«ä¿æŒ
            if os.path.exists(save_path):
                with open(save_path, 'r') as f:
                    baseline_results[f"{gender}_{impression}"] = json.load(f)

    # -------------------------------------------------
    # 2. Model Evaluation (Reconstruction FID, ArcFace, IRS)
    # -------------------------------------------------
    print("\nğŸ”µ Step 2: Evaluating All Models...")
    
    gen_root_path = Path(args.gen_root)
    # gen_root/samples/exp_name/prompt_name/images...
    
    # å®Ÿé¨“ãƒ•ã‚©ãƒ«ãƒ€ã‚’èµ°æŸ» (samples/ä»¥ä¸‹)
    # æ§‹é€ : expname_model_step/prompt_dir/*.png
    
    all_metrics = []

    for exp_dir in sorted(gen_root_path.iterdir()):
        if not exp_dir.is_dir(): continue
        
        dir_name = exp_dir.name # ä¾‹: lora_baseline_stable-diffusion-v1-5_step5000
        
        # å®Ÿé¨“åã‚’æŠ½å‡º
        # é•·ã„ã‚­ãƒ¼ã‹ã‚‰é †ã«è©¦è¡Œã™ã‚‹ã“ã¨ã§ã€éƒ¨åˆ†ä¸€è‡´ï¼ˆsdxl_... ãŒ sdxl_..._trigger ã«ãƒãƒƒãƒã™ã‚‹ç­‰ï¼‰ã‚’é˜²ã
        matched_exp_key = None
        sorted_keys = sorted(EXP_MAPPING.keys(), key=len, reverse=True)
        for key in sorted_keys:
            if dir_name.startswith(key):
                matched_exp_key = key
                break
        
        if not matched_exp_key:
            print(f"âš ï¸ Skipping unknown directory: {dir_name}")
            continue
            
        exp_id = EXP_MAPPING[matched_exp_key]
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã‚’èµ°æŸ»
        for prompt_dir in exp_dir.iterdir():
            if not prompt_dir.is_dir(): continue
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåã‹ã‚‰æ¡ä»¶(gender, impression)ã‚’æ¨å®š
            p_name = prompt_dir.name
            gender = "male" if "male" in p_name and "female" not in p_name else "female" if "female" in p_name else None
            impression = "high" if "high" in p_name else "low" if "low" in p_name else None
            
            if not gender or not impression:
                print(f"âš ï¸ Skipping ambiguous prompt: {p_name}")
                continue
                
            print(f"\nğŸ” Processing: [{exp_id}] {gender} / {impression}")
            
            # å¯¾å¿œã™ã‚‹æ­£è§£ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
            train_data_path = get_dataset_path(args.dataset_root, gender, impression)
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰ (CLIP Scoreç”¨)
            prompt_text = f"a photo of a {gender} face, {impression} score impression"
            if "trigger" in matched_exp_key:
                prompt_text = prompt_text.replace("a photo of", "a photo of ohwx")
            
            # çµæœä¿å­˜ãƒ‘ã‚¹
            metric_base_name = f"metrics_{matched_exp_key}_{gender}_{impression}"
            fid_json = os.path.join(args.output_dir, f"{metric_base_name}_fid.json")
            arc_json = os.path.join(args.output_dir, f"{metric_base_name}_arc.json")
            
            # A. FID / CLIP Calculation
            if not os.path.exists(fid_json):
                cmd_fid = (
                    f"python scripts/eval_lora_metrics.py "
                    f"--mode default "
                    f"--train_dir {train_data_path} "
                    f"--val_dir {train_data_path} " # Dummy (same as train)
                    f"--gen_dir {prompt_dir} "
                    f"--prompt \"{prompt_text}\" "
                    f"--output_json {fid_json}"
                )
                run_command(cmd_fid)
            
            # B. ArcFace / IRS Calculation
            if not os.path.exists(arc_json):
                cmd_arc = (
                    f"python scripts/eval_lora_metrics_vol2.py "
                    f"--train_dir {train_data_path} "
                    f"--gen_dir {prompt_dir} "
                    f"--output_json {arc_json}"
                )
                run_command(cmd_arc)
            
            # ãƒ‡ãƒ¼ã‚¿ã®é›†ç´„
            row = {
                "Exp_ID": exp_id,
                "Exp_Name": matched_exp_key,
                "Gender": gender,
                "Impression": impression,
            }
            
            if os.path.exists(fid_json):
                with open(fid_json, 'r') as f:
                    d = json.load(f)
                    row["Reconstruction_FID"] = d.get("quality_fid", -1)
                    row["CLIP_Score"] = d.get("clip_score", -1)
            
            if os.path.exists(arc_json):
                with open(arc_json, 'r') as f:
                    d = json.load(f)
                    row["ArcFace_Sim"] = d.get("arcface_similarity", -1)
                    row["IRS"] = d.get("irs_score", -1)
            
            all_metrics.append(row)

    # -------------------------------------------------
    # 3. Final Summary Report
    # -------------------------------------------------
    print("\nğŸ”µ Step 3: Generating Summary Report...")
    
    if all_metrics:
        df = pd.DataFrame(all_metrics)
        csv_path = os.path.join(args.output_dir, "final_evaluation_summary.csv")
        df.to_csv(csv_path, index=False)
        print(f"âœ… Summary saved to: {csv_path}")
        
        # Markdownå½¢å¼ã§ã‚‚è¡¨ç¤ºï¼ˆç¢ºèªç”¨ï¼‰
        print("\n" + df.to_markdown())
    else:
        print("âŒ No metrics collected.")

if __name__ == "__main__":
    main()
