import os
import argparse
import torch
from pathlib import Path
from diffusers import StableDiffusionPipeline, StableDiffusionXLPipeline, AutoencoderKL

# =================================================================
# è¨­å®š: å®Ÿé¨“ã”ã¨ã®è¨­å®šãƒ†ãƒ¼ãƒ–ãƒ«
# Key: å®Ÿé¨“ãƒ•ã‚©ãƒ«ãƒ€å
# Value: (ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ«ãƒ€å, SDXLãƒ•ãƒ©ã‚°, ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¹ãƒ†ãƒƒãƒ— or "latest")
# â€» ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¹ãƒ†ãƒƒãƒ—ãŒ "latest" ã®å ´åˆã§ã‚‚ã€args.default_step ãŒã‚ã‚Œã°ãã¡ã‚‰ã‚’å„ªå…ˆè©¦è¡Œã—ã¾ã™
# =================================================================
MAPPING = {
    "lora_baseline": ("stable-diffusion-v1-5", False, "latest"),
    "lora_rank4_lr5e5": ("stable-diffusion-v1-5", False, "latest"),
    "lora_rank16_batch16_A100": ("stable-diffusion-v1-5", False, "latest"),
    "lora_rank16_lr5e5": ("stable-diffusion-v1-5", False, "latest"),
    "lora_rank16_lr5e5_trigger_ohwx": ("stable-diffusion-v1-5", False, "latest"),
    "realvisxl_lora_rank16_prodigy": ("RealVisXL_V4.0", True, "latest"),
    "sdxl_lora_rank16_prodigy": ("sdxl-base-1.0", True, "latest"),
    "sdxl_lora_rank32_prodigy": ("sdxl-base-1.0", True, "latest"),
}
# =================================================================

def get_target_checkpoint(exp_dir, target_step_cfg, default_step=None):
    """æŒ‡å®šã•ã‚ŒãŸè¨­å®šã«åŸºã¥ã„ã¦ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‘ã‚¹ã‚’å–å¾—"""
    # å…¨ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå–å¾—
    checkpoints = sorted([d for d in exp_dir.iterdir() if d.name.startswith("checkpoint-")], 
                         key=lambda x: int(x.name.split("-")[1]))
    
    if not checkpoints:
        return None

    # ã‚¹ãƒ†ãƒƒãƒ—åã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
    ckpt_map = {int(d.name.split("-")[1]): d for d in checkpoints}

    # 1. è¾æ›¸ã§ã®å€‹åˆ¥æŒ‡å®šãŒã‚ã‚‹å ´åˆ (æ•°å€¤æŒ‡å®š)
    if isinstance(target_step_cfg, int):
        if target_step_cfg in ckpt_map:
            return ckpt_map[target_step_cfg]

    # 2. å¼•æ•°ã§ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæŒ‡å®šãŒã‚ã‚‹å ´åˆ (5000ç­‰)
    if default_step is not None:
        if default_step in ckpt_map:
            return ckpt_map[default_step]

    # 3. æŒ‡å®šãŒãªã„ã€ã¾ãŸã¯è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯æœ€æ–° (latest)
    return checkpoints[-1]

def generate_images(args):
    root_dir = Path(args.outputs_dir)
    models_root = Path(args.models_root)
    samples_root = root_dir / "samples"
    samples_root.mkdir(exist_ok=True)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    dtype = torch.float16 if device == "cuda" else torch.float32

    for exp_name, (base_name, is_sdxl, target_step_cfg) in MAPPING.items():
        exp_dir = root_dir / exp_name
        if not exp_dir.exists():
            print(f"â© Experiment directory {exp_name} not found. Skipping.")
            continue

        print(f"\nğŸš€ Processing: {exp_name}")
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç‰¹å®š
        ckpt_path = get_target_checkpoint(exp_dir, target_step_cfg, args.default_step)
        if not ckpt_path:
            print("   âš ï¸ No checkpoints found. Skipping.")
            continue
            
        step = ckpt_path.name.split("-")[1]
        
        # å‡ºåŠ›å…ˆãƒ‘ã‚¹ä½œæˆ (ãƒ•ã‚©ãƒ«ãƒ€åã«ä½¿ç”¨ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ˜è¨˜)
        save_dir_name = f"{exp_name}_{base_name}_step{step}"
        save_dir = samples_root / save_dir_name
        
        # æ—¢ã«å¿…è¦æšæ•°ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if save_dir.exists():
            existing = len(list(save_dir.glob("*.png")))
            if existing >= args.num_images:
                print(f"   âœ… Already has {existing} images. Skipping.")
                continue
        save_dir.mkdir(parents=True, exist_ok=True)

        base_model_path = models_root / base_name
        print(f"   ğŸ§© Base Model: {base_name} (SDXL: {is_sdxl})")
        print(f"   ğŸ“‚ Checkpoint: {ckpt_path.name}")
        print(f"   ğŸ’¾ Output: {save_dir}")

        try:
            # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰
            if is_sdxl:
                vae_path = "madebyollin/sdxl-vae-fp16-fix"
                pipe = StableDiffusionXLPipeline.from_pretrained(
                    str(base_model_path), 
                    torch_dtype=dtype, 
                    vae=AutoencoderKL.from_pretrained(vae_path, torch_dtype=dtype)
                )
                width, height = 1024, 1024
            else:
                pipe = StableDiffusionPipeline.from_pretrained(
                    str(base_model_path),
                    torch_dtype=dtype
                )
                width, height = 512, 512
            
            pipe.to(device)
            pipe.load_lora_weights(str(ckpt_path))
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª¿æ•´ (ãƒˆãƒªã‚¬ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¯¾å¿œ)
            prompt = args.prompt
            if "trigger" in exp_name.lower() and "ohwx" not in prompt:
                 prompt = prompt.replace("a photo of", "a photo of ohwx")
                 print(f"   ğŸª„ Trigger word detected. Using prompt: {prompt}")

            print(f"   ğŸ¨ Generating {args.num_images} images...")
            
            # ç”Ÿæˆãƒ«ãƒ¼ãƒ— (tqdmã‚’å»ƒæ­¢ã—ã€ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚­ã‚¹ãƒˆãƒ­ã‚°ã«å¤‰æ›´)
            for i in range(args.num_images):
                seed = torch.randint(0, 2**32 - 1, (1,)).item()
                generator = torch.Generator(device=device).manual_seed(seed)
                
                image = pipe(
                    prompt, 
                    num_inference_steps=30, 
                    height=height,
                    width=width,
                    generator=generator
                ).images[0]
                image.save(save_dir / f"{i:04d}_seed{seed}.png")
                
                # 100æšã”ã¨ã«é€²æ—ã‚’è¡¨ç¤º
                if (i + 1) % 100 == 0:
                    print(f"      - Progress: {i + 1}/{args.num_images} images generated.")
                
            del pipe
            torch.cuda.empty_cache()
            
        except Exception as e:
            print(f"   âŒ Error processing {exp_name}: {e}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Mass generate images for FID evaluation from LoRA checkpoints.")
    parser.add_argument("--outputs_dir", type=str, required=True, help="Path to diffusers/outputs")
    parser.add_argument("--models_root", type=str, required=True, help="Path to models directory")
    parser.add_argument("--num_images", type=int, default=1000, help="Number of images per model")
    parser.add_argument("--default_step", type=int, default=5000, help="Default step to use if available (fallback to latest)")
    parser.add_argument("--prompt", type=str, default="a photo of a male face, high score impression")
    
    args = parser.parse_args()
    generate_images(args)
